# src/orchestration/assets/ocr_parse.py
from dagster import op, Nothing, In, DagsterLogManager
from uuid import uuid4
import hashlib
import json
import os
import subprocess # To call pdftocairo/tesseract if needed
from urllib.parse import urlparse
from pathlib import Path
from sqlalchemy import text # Direct SQL for M1
from src.clients.db_client import db_session, fetch_one_sql, execute_sql

# Import parsers (ensure installed)
try:
    from PyPDF2 import PdfReader
    pypdf_available = True
except ImportError:
    PdfReader = None
    pypdf_available = False
try:
    import pytesseract
    from PIL import Image
    pytesseract_available = True
except ImportError:
    Image = None
    pytesseract_available = False

def _sha256_bytes(b: bytes) -> bytes:
    return hashlib.sha256(b).digest()

def _get_local_path_from_uri(uri: str, log: DagsterLogManager) -> Path | None:
    """Converts file URI to an absolute path inside the likely container env."""
    try:
        p = urlparse(uri)
        if p.scheme == "file" or not p.scheme:
            # Assume code runs in /app within Docker, map path accordingly
            relative_path = p.path.lstrip('/')
            abs_path = os.path.abspath(os.path.join('/app', relative_path))
            path_obj = Path(abs_path)
            if path_obj.exists():
                return path_obj
            else:
                log.error(f"File not found at expected path: {abs_path} (derived from URI: {uri})")
                return None
        else:
            log.warning(f"Non-local URI scheme in M1: {uri}. Skipping.")
            return None
    except Exception as e:
        log.error(f"Error parsing URI or checking path {uri}: {e}")
        return None

@op(ins={"doc_id": In(str)})
def ocr_parse(context, doc_id: str) -> Nothing:
    log: DagsterLogManager = context.log
    run_id = context.run_id

    with db_session() as s:
        doc_info = fetch_one_sql(s, """
            SELECT s.uri, s.mime_type
            FROM core.documents d JOIN core.sources s ON d.source_id = s.source_id
            WHERE d.doc_id = :doc_id AND d.status = 'ingested'
        """, {"doc_id": doc_id})

        if not doc_info:
            log.warning(f"Doc ID {doc_id} not found or not in 'ingested' state. Skipping parse.")
            return
        uri, mime = doc_info['uri'], doc_info['mime_type']

        path = _get_local_path_from_uri(uri, log)
        if not path:
            # Mark as failed if file couldn't be accessed
            execute_sql(s, "UPDATE core.documents SET status='failed', updated_at=NOW() WHERE doc_id=:doc_id", {"doc_id": doc_id})
            log.error(f"Failed to access source file for doc_id {doc_id}. Marked as failed.")
            return # Stop processing this document

        log.info(f"Processing file: {path} (MIME: {mime})")
        pages_data = []
        page_count = 0

        try:
            # --- PDF Processing ---
            if (mime == "application/pdf" or str(path).lower().endswith(".pdf")):
                if not pypdf_available:
                    log.warning("PyPDF2 not available. Cannot process PDF text layer.")
                else:
                    reader = PdfReader(str(path))
                    page_count = len(reader.pages)
                    log.info(f"PDF detected with {page_count} pages.")
                    for i, page in enumerate(reader.pages, start=1):
                        page_text = ""
                        ocr_attempted = False
                        try:
                            extracted = page.extract_text()
                            if extracted:
                                page_text = extracted.strip()
                        except Exception as text_err:
                            log.warning(f"PyPDF2 text extraction failed for page {i}: {text_err}")

                        # Simple OCR fallback if text empty and tools available
                        if not page_text and pytesseract_available:
                            try:
                                log.info(f"Attempting OCR fallback for PDF page {i}...")
                                # Use pdftocairo (requires poppler-utils)
                                img_base = f"/tmp/{path.stem}_page_{i}" # Temp file inside container
                                img_png = f"{img_base}.png"
                                # Create single page image
                                cmd = ['pdftocairo', '-png', '-f', str(i), '-l', str(i), '-singlefile', str(path), img_base]
                                proc = subprocess.run(cmd, capture_output=True, text=True, check=False)
                                if proc.returncode == 0 and os.path.exists(img_png):
                                    page_text = pytesseract.image_to_string(Image.open(img_png)).strip()
                                    os.remove(img_png) # Clean up temp image
                                    ocr_attempted = True
                                else:
                                    log.warning(f"pdftocairo failed for page {i}. Stdout: {proc.stdout}, Stderr: {proc.stderr}")
                            except Exception as ocr_err:
                                log.error(f"OCR fallback failed for PDF page {i}: {ocr_err}")

                        content_hash_bytes = _sha256_bytes(page_text.encode("utf-8"))
                        pages_data.append({
                            "page_num": i, "dpi": None, "text": page_text,
                            "vision_features": {"ocr_attempted": ocr_attempted},
                            "content_hash": content_hash_bytes
                        })

            # --- Image Processing ---
            elif mime and mime.startswith("image/") and pytesseract_available and Image:
                log.info(f"Image detected: {path}")
                img = Image.open(path)
                page_text = pytesseract.image_to_string(img).strip()
                content_hash_bytes = _sha256_bytes(page_text.encode("utf-8"))
                pages_data.append({
                    "page_num": 1, "dpi": None, # Could get DPI from image metadata
                    "text": page_text,
                    "vision_features": {"ocr_attempted": True},
                    "content_hash": content_hash_bytes
                })
                page_count = 1
            else:
                log.warning(f"Unsupported mime type '{mime}' or parser/OCR unavailable for {path}. Skipping parsing.")
                # Keep status='ingested', don't mark as failed unless file access failed
                return

            # --- Write pages data and update document status ---
            if pages_data:
                inserted_count = 0
                for p_data in pages_data:
                    page_id = str(uuid4())
                    pk_json = json.dumps({"page_id": page_id})
                    after_json = json.dumps({"doc_id": doc_id, "page_num": p_data["page_num"], "text_len": len(p_data["text"])}) # Simplified
                    try:
                        # Insert/Update page using ON CONFLICT
                        execute_sql(s, """
                            INSERT INTO core.pages (page_id, doc_id, page_num, dpi, text, vision_features, content_hash)
                            VALUES (:pid, :doc_id::uuid, :n, :dpi, :text, :vf::jsonb, :hash)
                            ON CONFLICT (doc_id, page_num) DO UPDATE SET
                                text = EXCLUDED.text,
                                vision_features = EXCLUDED.vision_features,
                                content_hash = EXCLUDED.content_hash,
                                page_id = EXCLUDED.page_id -- Ensure page_id is updated if row existed
                        """, {
                            "pid": page_id, "doc_id": doc_id, "n": p_data["page_num"],
                            "dpi": p_data["dpi"], "text": p_data["text"],
                            "vf": json.dumps(p_data["vision_features"]), "hash": p_data["content_hash"]
                        })
                        # Log write set (simplified for M1)
                        execute_sql(s, """
                            INSERT INTO ops.write_sets (run_id, step, table_name, pk, op, after)
                            VALUES (:run_id::uuid, 'ocr_parse', 'core.pages', :pk::jsonb, 'UPSERT', :after::jsonb)
                        """, {"run_id": run_id, "pk": pk_json, "after": after_json})
                        inserted_count += 1
                    except Exception as insert_err:
                        log.error(f"Failed to insert/update page {p_data['page_num']} for doc {doc_id}: {insert_err}")
                        raise # Fail the whole op for M1 on DB error

                # Update document status only if pages were processed
                execute_sql(s,
                    "UPDATE core.documents SET status='parsed', updated_at=NOW() WHERE doc_id=:doc_id::uuid",
                    {"doc_id": doc_id}
                )
                # Log write set for document update
                pk_doc_json = json.dumps({"doc_id": doc_id})
                after_doc_json = json.dumps({"status": "parsed"}) # Simplified
                execute_sql(s, """
                    INSERT INTO ops.write_sets (run_id, step, table_name, pk, op, after)
                    VALUES (:run_id::uuid, 'ocr_parse', 'core.documents', :pk::jsonb, 'UPDATE', :after::jsonb)
                """, {"run_id": run_id, "pk": pk_doc_json, "after": after_doc_json})

                log.info(f"Parsed and wrote {inserted_count}/{page_count} pages for doc_id={doc_id}")
            else:
                log.warning(f"No pages extracted for doc_id={doc_id}. Document status remains 'ingested'.")

        except Exception as e:
            log.error(f"Error during parsing/OCR for doc_id {doc_id}: {e}", exc_info=True)
            # Mark document as failed
            try: # Use nested session/try block for safety
                 execute_sql(s, "UPDATE core.documents SET status='failed', updated_at=NOW() WHERE doc_id=:doc_id::uuid", {"doc_id": doc_id})
                 # Log write set for failure update
                 pk_doc_json = json.dumps({"doc_id": doc_id})
                 after_doc_json = json.dumps({"status": "failed"})
                 execute_sql(s, """
                     INSERT INTO ops.write_sets (run_id, step, table_name, pk, op, after)
                     VALUES (:run_id::uuid, 'ocr_parse', 'core.documents', :pk::jsonb, 'UPDATE', :after::jsonb)
                 """, {"run_id": run_id, "pk": pk_doc_json, "after": after_doc_json})
            except Exception as db_err:
                 log.error(f"Failed even to mark doc {doc_id} as failed: {db_err}")
            raise # Re-raise the original error to fail the Dagster run

        # Commit happens automatically when 'with db_session()' exits successfully